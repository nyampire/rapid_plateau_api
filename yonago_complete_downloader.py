#!/usr/bin/env python3
"""
ç±³å­å¸‚Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿å®Œå…¨å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼‰
153ä»¶ã®å…¨ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å–å¾—ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜

å…ƒãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: http://surveyor.mydns.jp/task-bldg/mesh/31202
å¯¾è±¡: ç±³å­å¸‚ã‚¨ãƒªã‚¢ã®2æ¬¡ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆ8æ¡ã‚³ãƒ¼ãƒ‰ï¼‰153ä»¶
"""

import requests
import os
import re
import logging
from pathlib import Path
from typing import List, Set, Dict, Tuple
import time
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('yonago_complete_downloader.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class YonagoCompleteDownloader:
    def __init__(self, output_dir="./yonago_plateau_data"):
        self.output_dir = Path(output_dir)
        self.base_url = "http://surveyor.mydns.jp/task-bldg/mesh/31202"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.output_dir.mkdir(exist_ok=True)
        logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir.absolute()}")
        
        # 153ä»¶ã®å…¨åˆ©ç”¨å¯èƒ½ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆç¢ºå®šãƒªã‚¹ãƒˆï¼‰
        self.all_available_meshes = [
            "53330256", "53330259", "53330265", "53330266", "53330267", "53330268", "53330269",
            "53330275", "53330276", "53330277", "53330278", "53330279", "53330285", "53330286",
            "53330287", "53330288", "53330289", "53330295", "53330296", "53330297", "53330298",
            "53330299", "53330350", "53330360", "53330363", "53330364", "53330365", "53330370",
            "53330371", "53330372", "53330373", "53330374", "53330375", "53330380", "53330381",
            "53330382", "53330383", "53330384", "53330385", "53330390", "53330391", "53330392",
            "53330393", "53330394", "53330395", "53330396", "53331169", "53331179", "53331189",
            "53331205", "53331206", "53331207", "53331208", "53331209", "53331215", "53331216",
            "53331217", "53331218", "53331219", "53331223", "53331224", "53331225", "53331226",
            "53331227", "53331228", "53331229", "53331231", "53331232", "53331233", "53331234",
            "53331235", "53331236", "53331237", "53331238", "53331239", "53331240", "53331241",
            "53331242", "53331243", "53331244", "53331245", "53331246", "53331247", "53331248",
            "53331249", "53331250", "53331251", "53331252", "53331253", "53331254", "53331255",
            "53331256", "53331257", "53331258", "53331259", "53331260", "53331261", "53331262",
            "53331263", "53331264", "53331265", "53331270", "53331271", "53331272", "53331273",
            "53331280", "53331281", "53331282", "53331290", "53331291", "53331300", "53331301",
            "53331302", "53331303", "53331304", "53331305", "53331306", "53331307", "53331310",
            "53331311", "53331312", "53331313", "53331314", "53331315", "53331316", "53331317",
            "53331318", "53331320", "53331321", "53331322", "53331323", "53331324", "53331325",
            "53331326", "53331327", "53331330", "53331331", "53331332", "53331333", "53331334",
            "53331335", "53331336", "53331341", "53331342", "53331343", "53331344", "53331345",
            "53331346", "53331353", "53331354", "53331355", "53331356", "53331364"
        ]
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šï¼ˆå®‰å®šæ€§é‡è¦–ï¼‰
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (compatible; OSMFJ-PlateauDownloader/1.0)',
            'Accept': 'application/zip, application/octet-stream, */*',
            'Accept-Encoding': 'gzip, deflate',
            'Accept-Language': 'ja,en;q=0.9',
            'Connection': 'keep-alive'
        })
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
        self.session.timeout = 60
        
        # ãƒªãƒˆãƒ©ã‚¤è¨­å®š
        retry_strategy = Retry(
            total=3,
            backoff_factor=2,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
    def analyze_current_status(self) -> Dict:
        """ç¾åœ¨ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ã‚’åˆ†æ"""
        logger.info("ğŸ” ç¾åœ¨ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ã‚’åˆ†æä¸­...")
        
        existing_files = list(self.output_dir.glob("*.zip"))
        existing_meshes = set()
        
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        for file in existing_files:
            match = re.match(r'^(\d+)\.zip$', file.name)
            if match:
                existing_meshes.add(match.group(1))
            else:
                # ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç•°ãªã‚‹å ´åˆã®å¯¾å¿œ
                match = re.search(r'(\d{8})', file.name)
                if match:
                    existing_meshes.add(match.group(1))
        
        missing_meshes = set(self.all_available_meshes) - existing_meshes
        
        status = {
            'total_available': len(self.all_available_meshes),
            'existing_count': len(existing_meshes),
            'missing_count': len(missing_meshes),
            'existing_meshes': sorted(existing_meshes),
            'missing_meshes': sorted(missing_meshes),
            'completion_rate': len(existing_meshes) / len(self.all_available_meshes) * 100
        }
        
        logger.info(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³:")
        logger.info(f"   åˆ©ç”¨å¯èƒ½ç·æ•°: {status['total_available']}ä»¶")
        logger.info(f"   æ—¢å­˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {status['existing_count']}ä»¶")
        logger.info(f"   æœªå–å¾—: {status['missing_count']}ä»¶")
        logger.info(f"   å®Œäº†ç‡: {status['completion_rate']:.1f}%")
        
        if status['missing_count'] > 0:
            logger.info(f"   æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ä¾‹: {', '.join(status['missing_meshes'][:10])}")
            if len(status['missing_meshes']) > 10:
                logger.info(f"   ... (ä»– {len(status['missing_meshes'])-10}ä»¶)")
        
        return status
    
    def verify_web_availability(self) -> List[str]:
        """Webã‚µã‚¤ãƒˆã‹ã‚‰åˆ©ç”¨å¯èƒ½ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å®‰å…¨ç¢ºèª"""
        logger.info("ğŸŒ Webã‚µã‚¤ãƒˆã‹ã‚‰åˆ©ç”¨å¯èƒ½ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å®‰å…¨ç¢ºèªä¸­...")
        
        try:
            # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚ã®å¾…æ©Ÿ
            logger.debug("â±ï¸ ã‚µãƒ¼ãƒãƒ¼ä¿è­·å¾…æ©Ÿ: 2ç§’")
            time.sleep(2.0)
            
            response = self.session.get(self.base_url, timeout=45)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # zipãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
            web_meshes = []
            for link in soup.find_all('a', href=True):
                href = link['href']
                if href.endswith('.zip') and re.match(r'^\d+\.zip$', href):
                    mesh_code = href.replace('.zip', '')
                    web_meshes.append(mesh_code)
            
            # æ—¢çŸ¥ãƒªã‚¹ãƒˆã¨æ¯”è¼ƒ
            web_set = set(web_meshes)
            known_set = set(self.all_available_meshes)
            
            only_web = web_set - known_set
            only_known = known_set - web_set
            common = web_set & known_set
            
            logger.info(f"âœ… Webç¢ºèªçµæœ:")
            logger.info(f"   Webç™ºè¦‹: {len(web_meshes)}ä»¶")
            logger.info(f"   æ—¢çŸ¥ãƒªã‚¹ãƒˆ: {len(self.all_available_meshes)}ä»¶")
            logger.info(f"   å…±é€š: {len(common)}ä»¶")
            
            if only_web:
                logger.info(f"   Webã®ã¿: {len(only_web)}ä»¶")
                if len(only_web) <= 10:
                    logger.info(f"     æ–°ç™ºè¦‹: {sorted(only_web)}")
                else:
                    logger.info(f"     æ–°ç™ºè¦‹ä¾‹: {sorted(only_web)[:5]} (ä»–{len(only_web)-5}ä»¶)")
            
            if only_known:
                logger.info(f"   æ—¢çŸ¥ã®ã¿: {len(only_known)}ä»¶")
                if len(only_known) <= 10:
                    logger.info(f"     Webæ¬ å¦‚: {sorted(only_known)}")
                else:
                    logger.info(f"     Webæ¬ å¦‚ä¾‹: {sorted(only_known)[:5]} (ä»–{len(only_known)-5}ä»¶)")
            
            # ã‚ˆã‚Šå®Œå…¨ãªãƒªã‚¹ãƒˆã‚’ä½¿ç”¨ï¼ˆWebç™ºè¦‹ + æ—¢çŸ¥ï¼‰
            complete_list = sorted(list(web_set | known_set))
            logger.info(f"   çµ±åˆå¾Œç·æ•°: {len(complete_list)}ä»¶")
            
            return complete_list
            
        except Exception as e:
            logger.warning(f"âš ï¸ Webç¢ºèªå¤±æ•—ã€æ—¢çŸ¥ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨: {e}")
            logger.info(f"ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—¢çŸ¥ã®{len(self.all_available_meshes)}ä»¶ã‚’ä½¿ç”¨")
            return self.all_available_meshes
    
    def download_single_mesh(self, mesh_code: str) -> Tuple[str, bool, str, int]:
        """å˜ä¸€ãƒ¡ãƒƒã‚·ãƒ¥ã®å®‰å…¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒªãƒˆãƒ©ã‚¤ãƒ»æ¥ç¶šç¢ºèªä»˜ãï¼‰"""
        max_retries = 3
        base_delay = 2.0  # åŸºæœ¬å¾…æ©Ÿæ™‚é–“
        
        for attempt in range(max_retries):
            try:
                url = f"{self.base_url}/{mesh_code}.zip"
                file_path = self.output_dir / f"{mesh_code}.zip"
                
                # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
                if file_path.exists():
                    file_size = file_path.stat().st_size
                    if file_size > 1000:  # 1KBä»¥ä¸Šãªã‚‰æœ‰åŠ¹ã¨ã¿ãªã™
                        return mesh_code, True, "already_exists", file_size
                    else:
                        # ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹å ´åˆã¯å‰Šé™¤ã—ã¦å†è©¦è¡Œ
                        file_path.unlink()
                        logger.debug(f"ğŸ—‘ï¸ ä¸å®Œå…¨ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {mesh_code}")
                
                # æ¥ç¶šå‰ã®å¾…æ©Ÿï¼ˆã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ï¼‰
                if attempt > 0:
                    delay = base_delay * (2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    logger.debug(f"â±ï¸ ãƒªãƒˆãƒ©ã‚¤å‰å¾…æ©Ÿ: {mesh_code} - {delay}ç§’")
                    time.sleep(delay)
                else:
                    # åˆå›ã§ã‚‚å°‘ã—å¾…æ©Ÿ
                    time.sleep(0.5)
                
                # ã¾ãšHEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
                logger.debug(f"ğŸ” [{attempt+1}/{max_retries}] å­˜åœ¨ç¢ºèª: {mesh_code}")
                head_response = self.session.head(url, timeout=30)
                
                if head_response.status_code == 404:
                    return mesh_code, False, "file_not_found", 0
                elif head_response.status_code != 200:
                    # 200ä»¥å¤–ã®å ´åˆã¯æ¬¡ã®è©¦è¡Œã¸
                    if attempt < max_retries - 1:
                        logger.debug(f"âš ï¸ HEADå¿œç­” {head_response.status_code}: {mesh_code} - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                        continue
                    else:
                        return mesh_code, False, f"head_error_{head_response.status_code}", 0
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
                content_length = head_response.headers.get('content-length')
                if content_length:
                    expected_size = int(content_length)
                    if expected_size < 1000:  # 1KBæœªæº€ã¯ç•°å¸¸
                        return mesh_code, False, "file_too_small_on_server", 0
                    logger.debug(f"ğŸ“ äºˆæƒ³ã‚µã‚¤ã‚º: {mesh_code} - {expected_size:,}bytes")
                
                # å®Ÿéš›ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                logger.debug(f"ğŸ“¥ [{attempt+1}/{max_retries}] ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {mesh_code}")
                response = self.session.get(url, timeout=120, stream=True)
                response.raise_for_status()
                
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºå°ã•ã‚ï¼‰
                downloaded_size = 0
                chunk_size = 4096  # 4KBï¼ˆå°ã•ã‚ã§å®‰å®šæ€§é‡è¦–ï¼‰
                
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            
                            # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯é€”ä¸­ã§å°ä¼‘æ­¢
                            if downloaded_size % (chunk_size * 50) == 0:  # 200KBæ¯
                                time.sleep(0.01)
                
                final_size = file_path.stat().st_size
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸç¢ºèª
                if final_size > 1000:  # æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                    logger.debug(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {mesh_code} - {final_size:,}bytes")
                    return mesh_code, True, "downloaded", final_size
                else:
                    file_path.unlink()  # ä¸å®Œå…¨ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    if attempt < max_retries - 1:
                        logger.debug(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç•°å¸¸: {mesh_code} - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                        continue
                    else:
                        return mesh_code, False, "downloaded_file_too_small", 0
                        
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    logger.debug(f"â±ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {mesh_code} - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                    continue
                else:
                    return mesh_code, False, "timeout_error", 0
                    
            except requests.exceptions.ConnectionError:
                if attempt < max_retries - 1:
                    logger.debug(f"ğŸ”Œ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {mesh_code} - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                    time.sleep(base_delay * 2)  # æ¥ç¶šã‚¨ãƒ©ãƒ¼ã¯é•·ã‚ã«å¾…æ©Ÿ
                    continue
                else:
                    return mesh_code, False, "connection_error", 0
                    
            except requests.RequestException as e:
                if attempt < max_retries - 1:
                    logger.debug(f"ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {mesh_code} - {str(e)} - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                    continue
                else:
                    return mesh_code, False, f"network_error: {str(e)}", 0
                    
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.debug(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {mesh_code} - {str(e)} - ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™")
                    continue
                else:
                    return mesh_code, False, f"unexpected_error: {str(e)}", 0
        
        # ã“ã“ã«åˆ°é”ã™ã‚‹ã“ã¨ã¯ãªã„ã¯ãšã ãŒã€å®‰å…¨ã®ãŸã‚
        return mesh_code, False, "max_retries_exceeded", 0
    
    def download_missing_meshes(self, missing_meshes: List[str]) -> Dict:
        """æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ã®å®‰å…¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†ï¼‰"""
        if not missing_meshes:
            logger.info("ğŸ“¥ æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ã¯ã‚ã‚Šã¾ã›ã‚“")
            return {'success': [], 'failed': [], 'total_size': 0}
        
        logger.info(f"ğŸ“¥ æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ {len(missing_meshes)}ä»¶ã‚’å®‰å…¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        logger.info("ğŸŒ ã‚µãƒ¼ãƒãƒ¼å®‰å®šæ€§ã‚’è€ƒæ…®ã—ã¦ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†ã‚’å®Ÿè¡Œ")
        
        success_list = []
        failed_list = []
        total_size = 0
        
        # ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†ï¼ˆä¸¦åˆ—å‡¦ç†ã¯åœæ­¢ï¼‰
        for i, mesh_code in enumerate(missing_meshes, 1):
            try:
                # é€²æ—è¡¨ç¤º
                progress = i / len(missing_meshes) * 100
                logger.info(f"ğŸ“¥ [{i:3d}/{len(missing_meshes)}] å‡¦ç†ä¸­: {mesh_code} ({progress:.1f}%)")
                
                # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚ã®å¾…æ©Ÿ
                if i > 1:  # 2ç•ªç›®ä»¥é™
                    wait_time = 1.5  # 1.5ç§’é–“éš”
                    logger.debug(f"â±ï¸ ã‚µãƒ¼ãƒãƒ¼ä¿è­·å¾…æ©Ÿ: {wait_time}ç§’")
                    time.sleep(wait_time)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                mesh_code, success, message, size = self.download_single_mesh(mesh_code)
                
                if success:
                    success_list.append(mesh_code)
                    total_size += size
                    if message == "downloaded":
                        logger.info(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {mesh_code} ({size:,}bytes)")
                    else:
                        logger.info(f"â­ï¸ æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {mesh_code} ({size:,}bytes)")
                else:
                    failed_list.append((mesh_code, message))
                    logger.warning(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {mesh_code} - {message}")
                    
                    # å¤±æ•—æ™‚ã¯å°‘ã—é•·ã‚ã«å¾…æ©Ÿ
                    if "404" not in message and "not_found" not in message:
                        logger.debug("â±ï¸ å¤±æ•—å¾Œè¿½åŠ å¾…æ©Ÿ: 3ç§’")
                        time.sleep(3.0)
                
                # 10ä»¶æ¯ã«ä¸­é–“ãƒ¬ãƒãƒ¼ãƒˆ
                if i % 10 == 0:
                    logger.info(f"ğŸ“Š ä¸­é–“é€²æ—: æˆåŠŸ{len(success_list)}, å¤±æ•—{len(failed_list)}, æ®‹ã‚Š{len(missing_meshes)-i}")
                
                # 20ä»¶æ¯ã«å°ä¼‘æ­¢
                if i % 20 == 0:
                    logger.info("ğŸ˜´ ã‚µãƒ¼ãƒãƒ¼ä¿è­·ã®ãŸã‚ã®å°ä¼‘æ­¢: 5ç§’")
                    time.sleep(5.0)
                    
            except KeyboardInterrupt:
                logger.warning("âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸­æ–­ - ç¾åœ¨ã¾ã§ã®çµæœã‚’è¿”ã—ã¾ã™")
                break
            except Exception as e:
                failed_list.append((mesh_code, f"processing_error: {str(e)}"))
                logger.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {mesh_code} - {e}")
                continue
        
        result = {
            'success': success_list,
            'failed': failed_list,
            'total_size': total_size
        }
        
        logger.info(f"ğŸ“Š ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ:")
        logger.info(f"   æˆåŠŸ: {len(success_list)}ä»¶")
        logger.info(f"   å¤±æ•—: {len(failed_list)}ä»¶")
        logger.info(f"   æˆåŠŸç‡: {len(success_list)/(len(success_list)+len(failed_list))*100:.1f}%")
        logger.info(f"   åˆè¨ˆã‚µã‚¤ã‚º: {total_size:,}bytes ({total_size/1024/1024:.1f}MB)")
        
        # å¤±æ•—è©³ç´°ã®åˆ†æ
        if failed_list:
            failure_types = {}
            for mesh, reason in failed_list:
                failure_type = reason.split(':')[0] if ':' in reason else reason
                failure_types[failure_type] = failure_types.get(failure_type, 0) + 1
            
            logger.warning(f"   å¤±æ•—åˆ†æ:")
            for failure_type, count in sorted(failure_types.items(), key=lambda x: x[1], reverse=True):
                logger.warning(f"     {failure_type}: {count}ä»¶")
            
            # å¤±æ•—ãƒ¡ãƒƒã‚·ãƒ¥ã®è©³ç´°è¡¨ç¤ºï¼ˆæœ€åˆã®5ä»¶ï¼‰
            logger.warning(f"   å¤±æ•—ãƒ¡ãƒƒã‚·ãƒ¥ä¾‹:")
            for mesh, reason in failed_list[:5]:
                logger.warning(f"     {mesh}: {reason}")
            if len(failed_list) > 5:
                logger.warning(f"     ... (ä»– {len(failed_list)-5}ä»¶)")
        
        return result
    
    def create_download_report(self, initial_status: Dict, download_result: Dict):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        report_file = self.output_dir / "download_report.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# ç±³å­å¸‚Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿å®Œå…¨å–å¾—ãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write(f"# å®Ÿè¡Œæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# å…ƒãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {self.base_url}\n\n")
            
            f.write("## å–å¾—å‰çŠ¶æ³\n")
            f.write(f"åˆ©ç”¨å¯èƒ½ç·ãƒ¡ãƒƒã‚·ãƒ¥: {initial_status['total_available']}ä»¶\n")
            f.write(f"æ—¢å­˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {initial_status['existing_count']}ä»¶\n")
            f.write(f"æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥: {initial_status['missing_count']}ä»¶\n")
            f.write(f"å®Œäº†ç‡: {initial_status['completion_rate']:.1f}%\n\n")
            
            f.write("## ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œçµæœ\n")
            f.write(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {len(download_result['success'])}ä»¶\n")
            f.write(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {len(download_result['failed'])}ä»¶\n")
            f.write(f"å–å¾—ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {download_result['total_size']:,}bytes ({download_result['total_size']/1024/1024:.1f}MB)\n\n")
            
            # æœ€çµ‚çŠ¶æ³
            final_existing = initial_status['existing_count'] + len(download_result['success'])
            final_completion = final_existing / initial_status['total_available'] * 100
            
            f.write("## æœ€çµ‚çŠ¶æ³\n")
            f.write(f"ç·ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿: {final_existing}ä»¶\n")
            f.write(f"å®Œäº†ç‡: {final_completion:.1f}%\n")
            
            if final_completion >= 100.0:
                f.write("âœ… å®Œå…¨ã‚«ãƒãƒ¬ãƒƒã‚¸é”æˆï¼\n")
            else:
                remaining = initial_status['total_available'] - final_existing
                f.write(f"âš ï¸ æ®‹ã‚Šæœªå–å¾—: {remaining}ä»¶\n")
            
            f.write("\n## æˆåŠŸãƒ¡ãƒƒã‚·ãƒ¥ä¸€è¦§\n")
            for mesh in sorted(download_result['success']):
                f.write(f"{mesh}.zip\n")
            
            if download_result['failed']:
                f.write("\n## å¤±æ•—ãƒ¡ãƒƒã‚·ãƒ¥ä¸€è¦§\n")
                for mesh, reason in download_result['failed']:
                    f.write(f"{mesh}: {reason}\n")
        
        logger.info(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ: {report_file}")
    
    def run_complete_download(self):
        """å®Œå…¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        logger.info("ğŸš€ ç±³å­å¸‚Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿å®Œå…¨å–å¾—é–‹å§‹")
        logger.info("=" * 60)
        logger.info("ğŸ“Š å¯¾è±¡: 153ä»¶ã®2æ¬¡ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆç±³å­å¸‚å…¨åŸŸï¼‰")
        logger.info("ğŸ¯ ç›®æ¨™: å…¨ãƒ¡ãƒƒã‚·ãƒ¥ã®å®Œå…¨å–å¾—")
        logger.info("=" * 60)
        
        try:
            # Phase 1: ç¾çŠ¶åˆ†æ
            logger.info("\nğŸ“Š Phase 1: ç¾åœ¨ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³åˆ†æ")
            initial_status = self.analyze_current_status()
            
            # Phase 2: Webå¯ç”¨æ€§ç¢ºèª
            logger.info("\nğŸŒ Phase 2: Webå¯ç”¨æ€§ç¢ºèª")
            verified_meshes = self.verify_web_availability()
            
            # æœ€æ–°ã®ãƒ¡ãƒƒã‚·ãƒ¥ãƒªã‚¹ãƒˆã§å†åˆ†æ
            existing_files = list(self.output_dir.glob("*.zip"))
            existing_meshes = set()
            for file in existing_files:
                match = re.match(r'^(\d+)\.zip$', file.name)
                if match and match.group(1) in verified_meshes:
                    existing_meshes.add(match.group(1))
            
            missing_meshes = list(set(verified_meshes) - existing_meshes)
            
            if not missing_meshes:
                logger.info("ğŸ‰ æ—¢ã«å…¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã™ï¼")
                self.create_download_report(initial_status, {'success': [], 'failed': [], 'total_size': 0})
                return True
            
            # Phase 3: æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            logger.info(f"\nğŸ“¥ Phase 3: æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ({len(missing_meshes)}ä»¶)")
            download_result = self.download_missing_meshes(missing_meshes)
            
            # Phase 4: ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            logger.info(f"\nğŸ“‹ Phase 4: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")
            self.create_download_report(initial_status, download_result)
            
            # Phase 5: æœ€çµ‚ç¢ºèª
            logger.info(f"\nğŸ” Phase 5: æœ€çµ‚ç¢ºèª")
            final_status = self.analyze_current_status()
            
            # çµæœåˆ¤å®š
            success = final_status['completion_rate'] >= 100.0
            
            logger.info("=" * 60)
            if success:
                logger.info("ğŸ‰ ç±³å­å¸‚Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿å®Œå…¨å–å¾—æˆåŠŸ!")
                logger.info("âœ… 153ä»¶ã®å…¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                logger.info("ğŸš€ æ¬¡ã¯ yonago_complete_importer.py ã§DBã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œ")
            else:
                logger.warning("âš ï¸ ä¸€éƒ¨ãƒ¡ãƒƒã‚·ãƒ¥ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                logger.info(f"ğŸ“Š é”æˆç‡: {final_status['completion_rate']:.1f}%")
                logger.info("ğŸ”„ å¤±æ•—åˆ†ã¯å¾Œã§å†å®Ÿè¡Œå¯èƒ½ã§ã™")
            
            logger.info("=" * 60)
            return success
            
        except Exception as e:
            logger.error(f"âŒ å®Œå…¨å–å¾—å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ç±³å­å¸‚Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿å®Œå…¨å–å¾—')
    parser.add_argument('--output-dir', default='./yonago_plateau_data',
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: ./yonago_plateau_data)')
    parser.add_argument('--verbose', action='store_true',
                       help='è©³ç´°ãƒ­ã‚°å‡ºåŠ›')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    logger.info("ğŸ“¥ ç±³å­å¸‚Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿å®Œå…¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼èµ·å‹•")
    
    downloader = YonagoCompleteDownloader(args.output_dir)
    success = downloader.run_complete_download()
    
    if success:
        logger.info("âœ… å®Œå…¨å–å¾—æˆåŠŸï¼æ¬¡ã¯ yonago_complete_importer.py ã§DBã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        print("\nğŸ‰ å®Œå…¨å–å¾—æˆåŠŸ!")
        print("ğŸ“ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å ´æ‰€: ./yonago_plateau_data/")
        print("ğŸš€ æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰: python3.9 yonago_complete_importer.py")
    else:
        logger.error("âŒ å®Œå…¨å–å¾—ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        print("\nâŒ ä¸€éƒ¨ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print("ğŸ“‹ è©³ç´°: yonago_complete_downloader.log ã‚’ç¢ºèª")
        print("ğŸ”„ å†å®Ÿè¡Œã§ç¶šãã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½")

if __name__ == "__main__":
    main()