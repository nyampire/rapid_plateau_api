#!/usr/bin/env python3
"""
Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼
surveyor.mydns.jp ã‹ã‚‰æŒ‡å®šå¸‚åŒºç”ºæ‘ã®ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜

ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: http://surveyor.mydns.jp/task-bldg/
å¯¾è±¡: å…¨å›½289å¸‚åŒºç”ºæ‘ã®Plateauãƒ‡ãƒ¼ã‚¿

ä½¿ç”¨ä¾‹:
  # åˆ©ç”¨å¯èƒ½ãªå¸‚åŒºç”ºæ‘ä¸€è¦§ã‚’è¡¨ç¤º
  python plateau_downloader.py --list

  # å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰æŒ‡å®šã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  python plateau_downloader.py --citycode 31202

  # å¸‚åŒºç”ºæ‘åã§æ¤œç´¢ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
  python plateau_downloader.py --cityname ç±³å­

  # å‡ºåŠ›å…ˆæŒ‡å®š
  python plateau_downloader.py --citycode 13101 --output-dir ./chiyoda_data
"""

import requests
import os
import re
import json
import logging
from pathlib import Path
from typing import List, Set, Dict, Tuple, Optional
import time
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('plateau_downloader.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class PlateauDownloader:
    """Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿æ±ç”¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼"""

    CITY_LIST_URL = "http://surveyor.mydns.jp/task-bldg/city"
    MESH_URL_TEMPLATE = "http://surveyor.mydns.jp/task-bldg/mesh/{citycode}"
    DATA_BASE_URL = "https://surveyor.mydns.jp/osm-data"

    def __init__(self, citycode: str, output_dir: Optional[str] = None):
        """
        Args:
            citycode: å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ (ä¾‹: "31202")
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€‚Noneã®å ´åˆã¯ ./plateau_data/{citycode} ã‚’ä½¿ç”¨
        """
        self.citycode = citycode
        self.city_info = None  # fetch_city_info ã§è¨­å®š
        self.folder = None     # fetch_city_info ã§è¨­å®š

        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = Path(f"./plateau_data/{citycode}")

        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (compatible; OSMFJ-PlateauDownloader/2.0)',
            'Accept': 'application/zip, application/octet-stream, */*',
            'Accept-Encoding': 'gzip, deflate',
            'Accept-Language': 'ja,en;q=0.9',
            'Connection': 'keep-alive'
        })
        self.session.timeout = 60

        # ãƒªãƒˆãƒ©ã‚¤è¨­å®š
        retry_strategy = Retry(
            total=3,
            backoff_factor=2,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    @classmethod
    def fetch_city_list(cls) -> List[Dict]:
        """ã‚µã‚¤ãƒˆã‹ã‚‰å¸‚åŒºç”ºæ‘ä¸€è¦§ã‚’å–å¾—"""
        logger.info("ğŸŒ å¸‚åŒºç”ºæ‘ä¸€è¦§ã‚’å–å¾—ä¸­...")

        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (compatible; OSMFJ-PlateauDownloader/2.0)'
        })

        response = session.get(cls.CITY_LIST_URL, timeout=30)
        response.raise_for_status()

        # JavaScriptã®citiesé…åˆ—ã‚’æŠ½å‡º
        content = response.text
        match = re.search(r'const\s+cities\s*=\s*(\[.*?\]);', content, re.DOTALL)
        if not match:
            raise RuntimeError("å¸‚åŒºç”ºæ‘ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")

        cities_json = match.group(1)
        # JavaScriptã®JSONé¢¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã«å¤‰æ›ç­‰ï¼‰
        # å®Ÿéš›ã«ã¯JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã€å¤±æ•—ã—ãŸã‚‰æ­£è¦è¡¨ç¾ã§æŠ½å‡º
        try:
            cities = json.loads(cities_json)
        except json.JSONDecodeError:
            # JavaScriptå½¢å¼ã®å ´åˆã€å€‹åˆ¥ã«æŠ½å‡º
            cities = cls._parse_cities_js(cities_json)

        logger.info(f"âœ… {len(cities)}ä»¶ã®å¸‚åŒºç”ºæ‘ã‚’å–å¾—")
        return cities

    @classmethod
    def _parse_cities_js(cls, js_text: str) -> List[Dict]:
        """JavaScripté…åˆ—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¸‚åŒºç”ºæ‘ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        cities = []
        # å„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æŠ½å‡º
        pattern = r'\{[^}]*?citycode[^}]*?\}'
        for obj_match in re.finditer(pattern, js_text, re.DOTALL):
            obj_text = obj_match.group()
            city = {}
            for key in ['citycode', 'cityname', 'folder', 'status', 'lng', 'lat']:
                val_match = re.search(rf'"{key}"\s*:\s*"([^"]*)"', obj_text)
                if not val_match:
                    val_match = re.search(rf"'{key}'\s*:\s*'([^']*)'", obj_text)
                if val_match:
                    city[key] = val_match.group(1)
                else:
                    # æ•°å€¤ã®å ´åˆ
                    val_match = re.search(rf'"{key}"\s*:\s*([\d.]+)', obj_text)
                    if val_match:
                        city[key] = val_match.group(1)
            if 'citycode' in city:
                cities.append(city)
        return cities

    def fetch_city_info(self) -> Dict:
        """æŒ‡å®šå¸‚åŒºç”ºæ‘ã®æƒ…å ±ã‚’å–å¾—"""
        cities = self.fetch_city_list()

        for city in cities:
            if city.get('citycode') == self.citycode:
                self.city_info = city
                self.folder = city.get('folder', '')
                logger.info(f"âœ… å¯¾è±¡å¸‚åŒºç”ºæ‘: {city.get('cityname', '')} ({self.citycode})")
                logger.info(f"   ãƒ•ã‚©ãƒ«ãƒ€: {self.folder}")
                logger.info(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {city.get('status', 'unknown')}")
                return city

        raise ValueError(f"å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ '{self.citycode}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    def fetch_mesh_list(self) -> List[Dict]:
        """ãƒ¡ãƒƒã‚·ãƒ¥ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ä¸€è¦§ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’å–å¾—"""
        mesh_url = self.MESH_URL_TEMPLATE.format(citycode=self.citycode)
        logger.info(f"ğŸŒ ãƒ¡ãƒƒã‚·ãƒ¥ä¸€è¦§ã‚’å–å¾—ä¸­: {mesh_url}")

        time.sleep(2.0)  # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›
        response = self.session.get(mesh_url, timeout=45)
        response.raise_for_status()

        content = response.text

        # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’JavaScripté…åˆ—ã‹ã‚‰æŠ½å‡º
        meshes = []
        match = re.search(r'const\s+meshes\s*=\s*(\[.*?\]);', content, re.DOTALL)
        if match:
            try:
                meshes = json.loads(match.group(1))
            except json.JSONDecodeError:
                meshes = self._parse_meshes_js(match.group(1))

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’HTMLã®ãƒªãƒ³ã‚¯ã‹ã‚‰ã‚‚åé›†
        download_urls = {}
        for link_match in re.finditer(r'href="([^"]*?\.zip)"', content):
            url = link_match.group(1)
            # ãƒ¡ãƒƒã‚·ãƒ¥ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            code_match = re.search(r'/(\d+)_bldg_', url)
            if code_match:
                download_urls[code_match.group(1)] = url

        # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã‚’ä»˜ä¸
        for mesh in meshes:
            meshcode = mesh.get('meshcode', '')
            if meshcode in download_urls:
                mesh['download_url'] = download_urls[meshcode]
            elif self.folder:
                # URLã‚’æ§‹ç¯‰
                mesh['download_url'] = (
                    f"{self.DATA_BASE_URL}/{self.folder}/bldg/"
                    f"{meshcode}_bldg_6697_op.zip"
                )

        logger.info(f"âœ… {len(meshes)}ä»¶ã®ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å–å¾—")
        if download_urls:
            logger.info(f"   ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLç¢ºèªæ¸ˆã¿: {len(download_urls)}ä»¶")

        return meshes

    def _parse_meshes_js(self, js_text: str) -> List[Dict]:
        """JavaScripté…åˆ—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        meshes = []
        pattern = r'\{[^}]*?meshcode[^}]*?\}'
        for obj_match in re.finditer(pattern, js_text, re.DOTALL):
            obj_text = obj_match.group()
            mesh = {}
            for key in ['meshcode', 'status', 'version']:
                val_match = re.search(rf'"{key}"\s*:\s*"([^"]*)"', obj_text)
                if not val_match:
                    val_match = re.search(rf"'{key}'\s*:\s*'([^']*)'", obj_text)
                if val_match:
                    mesh[key] = val_match.group(1)
            if 'meshcode' in mesh:
                meshes.append(mesh)
        return meshes

    def analyze_current_status(self, available_meshes: List[str]) -> Dict:
        """ç¾åœ¨ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ã‚’åˆ†æ"""
        logger.info("ğŸ” ç¾åœ¨ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ã‚’åˆ†æä¸­...")

        existing_files = list(self.output_dir.glob("*.zip"))
        existing_meshes = set()

        for file in existing_files:
            # meshcode_bldg_6697_op.zip å½¢å¼
            match = re.match(r'^(\d+)_bldg_', file.name)
            if match:
                existing_meshes.add(match.group(1))
            else:
                # meshcode.zip å½¢å¼
                match = re.match(r'^(\d+)\.zip$', file.name)
                if match:
                    existing_meshes.add(match.group(1))

        available_set = set(available_meshes)
        existing_matched = existing_meshes & available_set
        missing_meshes = available_set - existing_meshes

        total = len(available_meshes)
        status = {
            'total_available': total,
            'existing_count': len(existing_matched),
            'missing_count': len(missing_meshes),
            'existing_meshes': sorted(existing_matched),
            'missing_meshes': sorted(missing_meshes),
            'completion_rate': len(existing_matched) / total * 100 if total > 0 else 0
        }

        logger.info(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³:")
        logger.info(f"   åˆ©ç”¨å¯èƒ½ç·æ•°: {status['total_available']}ä»¶")
        logger.info(f"   æ—¢å­˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {status['existing_count']}ä»¶")
        logger.info(f"   æœªå–å¾—: {status['missing_count']}ä»¶")
        logger.info(f"   å®Œäº†ç‡: {status['completion_rate']:.1f}%")

        return status

    def download_single_mesh(self, mesh_info: Dict) -> Tuple[str, bool, str, int]:
        """å˜ä¸€ãƒ¡ãƒƒã‚·ãƒ¥ã®å®‰å…¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        meshcode = mesh_info.get('meshcode', '')
        download_url = mesh_info.get('download_url', '')
        max_retries = 3
        base_delay = 2.0

        if not download_url:
            return meshcode, False, "no_download_url", 0

        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’URLã‹ã‚‰å–å¾—
        filename = download_url.split('/')[-1]
        file_path = self.output_dir / filename

        for attempt in range(max_retries):
            try:
                # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
                if file_path.exists():
                    file_size = file_path.stat().st_size
                    if file_size > 1000:
                        return meshcode, True, "already_exists", file_size
                    else:
                        file_path.unlink()
                        logger.debug(f"ğŸ—‘ï¸ ä¸å®Œå…¨ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {meshcode}")

                # æ¥ç¶šå‰ã®å¾…æ©Ÿ
                if attempt > 0:
                    delay = base_delay * (2 ** attempt)
                    logger.debug(f"â±ï¸ ãƒªãƒˆãƒ©ã‚¤å‰å¾…æ©Ÿ: {meshcode} - {delay}ç§’")
                    time.sleep(delay)
                else:
                    time.sleep(0.5)

                # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
                logger.debug(f"ğŸ” [{attempt+1}/{max_retries}] å­˜åœ¨ç¢ºèª: {meshcode}")
                head_response = self.session.head(download_url, timeout=30)

                if head_response.status_code == 404:
                    return meshcode, False, "file_not_found", 0
                elif head_response.status_code != 200:
                    if attempt < max_retries - 1:
                        continue
                    else:
                        return meshcode, False, f"head_error_{head_response.status_code}", 0

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                logger.debug(f"ğŸ“¥ [{attempt+1}/{max_retries}] ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {meshcode}")
                response = self.session.get(download_url, timeout=120, stream=True)
                response.raise_for_status()

                downloaded_size = 0
                chunk_size = 4096

                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            if downloaded_size % (chunk_size * 50) == 0:
                                time.sleep(0.01)

                final_size = file_path.stat().st_size

                if final_size > 1000:
                    logger.debug(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {meshcode} - {final_size:,}bytes")
                    return meshcode, True, "downloaded", final_size
                else:
                    file_path.unlink()
                    if attempt < max_retries - 1:
                        continue
                    else:
                        return meshcode, False, "downloaded_file_too_small", 0

            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    continue
                else:
                    return meshcode, False, "timeout_error", 0

            except requests.exceptions.ConnectionError:
                if attempt < max_retries - 1:
                    time.sleep(base_delay * 2)
                    continue
                else:
                    return meshcode, False, "connection_error", 0

            except requests.RequestException as e:
                if attempt < max_retries - 1:
                    continue
                else:
                    return meshcode, False, f"network_error: {str(e)}", 0

            except Exception as e:
                if attempt < max_retries - 1:
                    continue
                else:
                    return meshcode, False, f"unexpected_error: {str(e)}", 0

        return meshcode, False, "max_retries_exceeded", 0

    def download_missing_meshes(self, mesh_list: List[Dict], missing_codes: List[str]) -> Dict:
        """æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ã®å®‰å…¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        # missing_codesã«è©²å½“ã™ã‚‹mesh_infoã‚’æŠ½å‡º
        missing_meshes = [m for m in mesh_list if m.get('meshcode') in missing_codes]

        if not missing_meshes:
            logger.info("ğŸ“¥ æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ã¯ã‚ã‚Šã¾ã›ã‚“")
            return {'success': [], 'failed': [], 'total_size': 0}

        logger.info(f"ğŸ“¥ æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ {len(missing_meshes)}ä»¶ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")

        success_list = []
        failed_list = []
        total_size = 0

        for i, mesh_info in enumerate(missing_meshes, 1):
            try:
                meshcode = mesh_info.get('meshcode', '')
                progress = i / len(missing_meshes) * 100
                logger.info(f"ğŸ“¥ [{i:3d}/{len(missing_meshes)}] å‡¦ç†ä¸­: {meshcode} ({progress:.1f}%)")

                if i > 1:
                    time.sleep(1.5)

                meshcode, success, message, size = self.download_single_mesh(mesh_info)

                if success:
                    success_list.append(meshcode)
                    total_size += size
                    if message == "downloaded":
                        logger.info(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {meshcode} ({size:,}bytes)")
                    else:
                        logger.info(f"â­ï¸ æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {meshcode} ({size:,}bytes)")
                else:
                    failed_list.append((meshcode, message))
                    logger.warning(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {meshcode} - {message}")
                    if "404" not in message and "not_found" not in message:
                        time.sleep(3.0)

                if i % 10 == 0:
                    logger.info(f"ğŸ“Š ä¸­é–“é€²æ—: æˆåŠŸ{len(success_list)}, å¤±æ•—{len(failed_list)}, æ®‹ã‚Š{len(missing_meshes)-i}")

                if i % 20 == 0:
                    logger.info("ğŸ˜´ ã‚µãƒ¼ãƒãƒ¼ä¿è­·ã®ãŸã‚ã®å°ä¼‘æ­¢: 5ç§’")
                    time.sleep(5.0)

            except KeyboardInterrupt:
                logger.warning("âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸­æ–­ - ç¾åœ¨ã¾ã§ã®çµæœã‚’è¿”ã—ã¾ã™")
                break
            except Exception as e:
                failed_list.append((mesh_info.get('meshcode', ''), f"processing_error: {str(e)}"))
                logger.error(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {mesh_info.get('meshcode', '')} - {e}")
                continue

        result = {
            'success': success_list,
            'failed': failed_list,
            'total_size': total_size
        }

        total_attempted = len(success_list) + len(failed_list)
        logger.info(f"ğŸ“Š ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ:")
        logger.info(f"   æˆåŠŸ: {len(success_list)}ä»¶")
        logger.info(f"   å¤±æ•—: {len(failed_list)}ä»¶")
        if total_attempted > 0:
            logger.info(f"   æˆåŠŸç‡: {len(success_list)/total_attempted*100:.1f}%")
        logger.info(f"   åˆè¨ˆã‚µã‚¤ã‚º: {total_size:,}bytes ({total_size/1024/1024:.1f}MB)")

        if failed_list:
            failure_types = {}
            for mesh, reason in failed_list:
                failure_type = reason.split(':')[0] if ':' in reason else reason
                failure_types[failure_type] = failure_types.get(failure_type, 0) + 1

            logger.warning(f"   å¤±æ•—åˆ†æ:")
            for failure_type, count in sorted(failure_types.items(), key=lambda x: x[1], reverse=True):
                logger.warning(f"     {failure_type}: {count}ä»¶")

        return result

    def create_download_report(self, initial_status: Dict, download_result: Dict):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        report_file = self.output_dir / "download_report.txt"
        cityname = self.city_info.get('cityname', self.citycode) if self.city_info else self.citycode

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ¬ãƒãƒ¼ãƒˆ: {cityname}\n")
            f.write(f"# å®Ÿè¡Œæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰: {self.citycode}\n")
            if self.folder:
                f.write(f"# ãƒ•ã‚©ãƒ«ãƒ€: {self.folder}\n")
            f.write("\n")

            f.write("## å–å¾—å‰çŠ¶æ³\n")
            f.write(f"åˆ©ç”¨å¯èƒ½ç·ãƒ¡ãƒƒã‚·ãƒ¥: {initial_status['total_available']}ä»¶\n")
            f.write(f"æ—¢å­˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {initial_status['existing_count']}ä»¶\n")
            f.write(f"æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥: {initial_status['missing_count']}ä»¶\n")
            f.write(f"å®Œäº†ç‡: {initial_status['completion_rate']:.1f}%\n\n")

            f.write("## ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œçµæœ\n")
            f.write(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {len(download_result['success'])}ä»¶\n")
            f.write(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {len(download_result['failed'])}ä»¶\n")
            f.write(f"å–å¾—ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {download_result['total_size']:,}bytes ({download_result['total_size']/1024/1024:.1f}MB)\n\n")

            final_existing = initial_status['existing_count'] + len(download_result['success'])
            total = initial_status['total_available']
            final_completion = final_existing / total * 100 if total > 0 else 0

            f.write("## æœ€çµ‚çŠ¶æ³\n")
            f.write(f"ç·ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿: {final_existing}ä»¶\n")
            f.write(f"å®Œäº†ç‡: {final_completion:.1f}%\n")

            if final_completion >= 100.0:
                f.write("âœ… å®Œå…¨ã‚«ãƒãƒ¬ãƒƒã‚¸é”æˆï¼\n")
            else:
                remaining = total - final_existing
                f.write(f"âš ï¸ æ®‹ã‚Šæœªå–å¾—: {remaining}ä»¶\n")

            f.write("\n## æˆåŠŸãƒ¡ãƒƒã‚·ãƒ¥ä¸€è¦§\n")
            for mesh in sorted(download_result['success']):
                f.write(f"{mesh}\n")

            if download_result['failed']:
                f.write("\n## å¤±æ•—ãƒ¡ãƒƒã‚·ãƒ¥ä¸€è¦§\n")
                for mesh, reason in download_result['failed']:
                    f.write(f"{mesh}: {reason}\n")

        logger.info(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ: {report_file}")

    def run(self):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        logger.info("ğŸš€ Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
        logger.info("=" * 60)

        try:
            # Phase 1: å¸‚åŒºç”ºæ‘æƒ…å ±å–å¾—
            logger.info("\nğŸ“Š Phase 1: å¸‚åŒºç”ºæ‘æƒ…å ±å–å¾—")
            self.fetch_city_info()
            cityname = self.city_info.get('cityname', self.citycode)
            logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir.absolute()}")

            # Phase 2: ãƒ¡ãƒƒã‚·ãƒ¥ä¸€è¦§å–å¾—
            logger.info("\nğŸŒ Phase 2: ãƒ¡ãƒƒã‚·ãƒ¥ä¸€è¦§å–å¾—")
            mesh_list = self.fetch_mesh_list()
            if not mesh_list:
                logger.error("âŒ ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False

            available_codes = [m.get('meshcode') for m in mesh_list if m.get('meshcode')]
            logger.info(f"   å¯¾è±¡: {cityname} ({len(available_codes)}ãƒ¡ãƒƒã‚·ãƒ¥)")

            # Phase 3: ç¾çŠ¶åˆ†æ
            logger.info("\nğŸ“Š Phase 3: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³åˆ†æ")
            initial_status = self.analyze_current_status(available_codes)

            if initial_status['missing_count'] == 0:
                logger.info("ğŸ‰ æ—¢ã«å…¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã™ï¼")
                self.create_download_report(initial_status, {'success': [], 'failed': [], 'total_size': 0})
                return True

            # Phase 4: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            logger.info(f"\nğŸ“¥ Phase 4: æœªå–å¾—ãƒ¡ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ({initial_status['missing_count']}ä»¶)")
            download_result = self.download_missing_meshes(mesh_list, initial_status['missing_meshes'])

            # Phase 5: ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            logger.info(f"\nğŸ“‹ Phase 5: ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")
            self.create_download_report(initial_status, download_result)

            # Phase 6: æœ€çµ‚ç¢ºèª
            logger.info(f"\nğŸ” Phase 6: æœ€çµ‚ç¢ºèª")
            final_status = self.analyze_current_status(available_codes)

            success = final_status['completion_rate'] >= 100.0

            logger.info("=" * 60)
            if success:
                logger.info(f"ğŸ‰ {cityname} Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ!")
                logger.info(f"âœ… {len(available_codes)}ä»¶ã®å…¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                logger.info("ğŸš€ æ¬¡ã¯ plateau_importer2postgis.py ã§DBã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œ")
            else:
                logger.warning("âš ï¸ ä¸€éƒ¨ãƒ¡ãƒƒã‚·ãƒ¥ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                logger.info(f"ğŸ“Š é”æˆç‡: {final_status['completion_rate']:.1f}%")
                logger.info("ğŸ”„ å†å®Ÿè¡Œã§ç¶šãã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™")
            logger.info("=" * 60)

            return success

        except Exception as e:
            logger.error(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return False


def print_city_list(cities: List[Dict], filter_text: Optional[str] = None):
    """å¸‚åŒºç”ºæ‘ä¸€è¦§ã‚’è¡¨ç¤º"""
    if filter_text:
        cities = [c for c in cities if filter_text in c.get('cityname', '') or filter_text in c.get('citycode', '')]

    if not cities:
        print("è©²å½“ã™ã‚‹å¸‚åŒºç”ºæ‘ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    print(f"\n{'ã‚³ãƒ¼ãƒ‰':>6}  {'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹':<12}  {'å¸‚åŒºç”ºæ‘å'}")
    print("-" * 60)
    for city in sorted(cities, key=lambda c: c.get('citycode', '')):
        code = city.get('citycode', '')
        name = city.get('cityname', '')
        status = city.get('status', '')
        print(f"{code:>6}  {status:<12}  {name}")
    print(f"\nåˆè¨ˆ: {len(cities)}ä»¶")


def run_all_cities(base_output_dir: Optional[str] = None, city_interval: int = 30):
    """å…¨å¸‚åŒºç”ºæ‘ã‚’é †æ¬¡ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    logger.info("ğŸŒ å…¨å¸‚åŒºç”ºæ‘ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
    logger.info("=" * 60)

    cities = PlateauDownloader.fetch_city_list()
    cities_sorted = sorted(cities, key=lambda c: c.get('citycode', ''))

    total = len(cities_sorted)
    logger.info(f"ğŸ“Š å¯¾è±¡: {total}å¸‚åŒºç”ºæ‘")
    logger.info(f"â±ï¸ å¸‚åŒºç”ºæ‘é–“ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«: {city_interval}ç§’")
    logger.info("=" * 60)

    success_cities = []
    failed_cities = []
    skipped_cities = []

    for i, city in enumerate(cities_sorted, 1):
        citycode = city.get('citycode', '')
        cityname = city.get('cityname', '')

        try:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ™ï¸ [{i}/{total}] {cityname} ({citycode})")
            logger.info(f"{'='*60}")

            if base_output_dir:
                output_dir = str(Path(base_output_dir) / citycode)
            else:
                output_dir = None  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ (./plateau_data/{citycode})

            downloader = PlateauDownloader(citycode, output_dir)

            try:
                success = downloader.run()
            except ValueError as e:
                logger.warning(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {cityname} ({citycode}) - {e}")
                skipped_cities.append((citycode, cityname, str(e)))
                continue

            if success:
                success_cities.append((citycode, cityname))
                logger.info(f"âœ… {cityname} å®Œäº†")
            else:
                failed_cities.append((citycode, cityname))
                logger.warning(f"âš ï¸ {cityname} ä¸€éƒ¨å¤±æ•—")

            # å¸‚åŒºç”ºæ‘é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«ï¼ˆæœ€å¾Œã®å¸‚åŒºç”ºæ‘ä»¥å¤–ï¼‰
            if i < total:
                logger.info(f"ğŸ˜´ æ¬¡ã®å¸‚åŒºç”ºæ‘ã¾ã§ {city_interval}ç§’ å¾…æ©Ÿä¸­...")
                time.sleep(city_interval)

        except KeyboardInterrupt:
            logger.warning(f"\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸­æ–­ ({i}/{total}å¸‚åŒºç”ºæ‘å‡¦ç†æ¸ˆã¿)")
            break
        except Exception as e:
            failed_cities.append((citycode, cityname))
            logger.error(f"âŒ {cityname} ({citycode}) ã‚¨ãƒ©ãƒ¼: {e}")
            if i < total:
                time.sleep(city_interval)
            continue

    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š å…¨å¸‚åŒºç”ºæ‘ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ")
    logger.info("=" * 60)
    logger.info(f"   æˆåŠŸ: {len(success_cities)}ä»¶")
    logger.info(f"   å¤±æ•—: {len(failed_cities)}ä»¶")
    logger.info(f"   ã‚¹ã‚­ãƒƒãƒ—: {len(skipped_cities)}ä»¶")
    logger.info(f"   åˆè¨ˆ: {len(success_cities) + len(failed_cities) + len(skipped_cities)}/{total}ä»¶")

    if failed_cities:
        logger.warning("   å¤±æ•—ä¸€è¦§:")
        for code, name in failed_cities:
            logger.warning(f"     {code} {name}")

    if skipped_cities:
        logger.info("   ã‚¹ã‚­ãƒƒãƒ—ä¸€è¦§:")
        for code, name, reason in skipped_cities:
            logger.info(f"     {code} {name}: {reason}")

    print(f"\nğŸ“Š çµæœ: æˆåŠŸ {len(success_cities)}, å¤±æ•— {len(failed_cities)}, ã‚¹ã‚­ãƒƒãƒ— {len(skipped_cities)}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description='Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼')
    group = parser.add_mutually_exclusive_group()
    group.add_argument('--citycode', help='å¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ (ä¾‹: 31202)')
    group.add_argument('--all', action='store_true', help='å…¨å¸‚åŒºç”ºæ‘ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
    parser.add_argument('--cityname', help='å¸‚åŒºç”ºæ‘åã§æ¤œç´¢ (éƒ¨åˆ†ä¸€è‡´)')
    parser.add_argument('--list', action='store_true', help='åˆ©ç”¨å¯èƒ½ãªå¸‚åŒºç”ºæ‘ä¸€è¦§ã‚’è¡¨ç¤º')
    parser.add_argument('--output-dir', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--city-interval', type=int, default=30,
                       help='--all æ™‚ã®å¸‚åŒºç”ºæ‘é–“ã®å¾…æ©Ÿç§’æ•° (default: 30)')
    parser.add_argument('--verbose', action='store_true', help='è©³ç´°ãƒ­ã‚°å‡ºåŠ›')

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # ä¸€è¦§è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
    if args.list or (not args.citycode and not args.all and args.cityname):
        cities = PlateauDownloader.fetch_city_list()
        print_city_list(cities, args.cityname)
        return

    # å…¨å¸‚åŒºç”ºæ‘ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if args.all:
        run_all_cities(args.output_dir, args.city_interval)
        return

    # å˜ä¸€å¸‚åŒºç”ºæ‘ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if not args.citycode:
        parser.print_help()
        print("\nä¾‹:")
        print("  python plateau_downloader.py --list                    # ä¸€è¦§è¡¨ç¤º")
        print("  python plateau_downloader.py --cityname ç±³å­           # åå‰ã§æ¤œç´¢")
        print("  python plateau_downloader.py --citycode 31202          # å˜ä¸€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        print("  python plateau_downloader.py --all                     # å…¨å¸‚åŒºç”ºæ‘ä¸€æ‹¬")
        print("  python plateau_downloader.py --all --city-interval 60  # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«60ç§’")
        return

    logger.info("ğŸ—ï¸ Plateauå»ºç‰©ãƒ‡ãƒ¼ã‚¿ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼èµ·å‹•")

    downloader = PlateauDownloader(args.citycode, args.output_dir)
    success = downloader.run()

    if success:
        print(f"\nğŸ‰ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ!")
        print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å ´æ‰€: {downloader.output_dir}")
        print(f"ğŸš€ æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰: python plateau_importer2postgis.py --data-dir {downloader.output_dir}")
    else:
        print("\nâŒ ä¸€éƒ¨ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print("ğŸ“‹ è©³ç´°: plateau_downloader.log ã‚’ç¢ºèª")
        print("ğŸ”„ å†å®Ÿè¡Œã§ç¶šãã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½")


if __name__ == "__main__":
    main()
